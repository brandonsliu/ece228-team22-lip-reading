{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T01:13:49.971386Z","iopub.status.busy":"2024-06-13T01:13:49.970985Z","iopub.status.idle":"2024-06-13T01:13:49.978255Z","shell.execute_reply":"2024-06-13T01:13:49.977294Z","shell.execute_reply.started":"2024-06-13T01:13:49.971354Z"},"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import torch\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import transforms\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import time\n","from tqdm.notebook import tqdm\n","import glob\n","import torchvision.io\n","from sklearn.metrics import accuracy_score, top_k_accuracy_score\n","import copy\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T01:10:17.900233Z","iopub.status.busy":"2024-06-13T01:10:17.899852Z","iopub.status.idle":"2024-06-13T01:10:17.918471Z","shell.execute_reply":"2024-06-13T01:10:17.917555Z","shell.execute_reply.started":"2024-06-13T01:10:17.900206Z"},"trusted":true},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(self, num_classes=500):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv3d(1, 64, kernel_size=(3, 3, 3), padding=1)\n","        self.bn1 = nn.BatchNorm3d(64)\n","        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n","\n","        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=1)\n","        self.bn2 = nn.BatchNorm3d(128)\n","        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n","\n","        self.conv3a = nn.Conv3d(128, 256, kernel_size=(3, 3, 3), padding=1)\n","        self.bn3a = nn.BatchNorm3d(256)\n","        self.conv3b = nn.Conv3d(256, 256, kernel_size=(3, 3, 3), padding=1)\n","        self.bn3b = nn.BatchNorm3d(256)\n","        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n","\n","        self.conv4a = nn.Conv3d(256, 512, kernel_size=(3, 3, 3), padding=1)\n","        self.bn4a = nn.BatchNorm3d(512)\n","        self.conv4b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=1)\n","        self.bn4b = nn.BatchNorm3d(512)\n","\n","        self.conv5a = nn.Conv3d(512, 512, kernel_size=(3, 3, 3))\n","        self.bn5a = nn.BatchNorm3d(512)\n","        self.conv5b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3))\n","        self.bn5b = nn.BatchNorm3d(512)\n","        self.pool4 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(2, 2, 2))\n","\n","        self.flatten = nn.Flatten()\n","\n","        self.fc6 = nn.Linear(512 * 2 * 2 * 2, 4096)\n","        self.fc7 = nn.Linear(4096, 1024)\n","        self.fc8 = nn.Linear(1024, num_classes)\n","        \n","        self.dropout = nn.Dropout(p=0.3)\n","        self.relu = nn.ReLU()\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        x = self.relu(self.bn1(self.conv1(x)))\n","        x = self.pool1(x)\n","\n","        x = self.relu(self.bn2(self.conv2(x)))\n","        x = self.pool2(x)\n","\n","        x = self.relu(self.bn3a(self.conv3a(x)))\n","        x = self.relu(self.bn3b(self.conv3b(x)))\n","        x = self.pool3(x)\n","\n","        x = self.relu(self.bn4a(self.conv4a(x)))\n","        x = self.relu(self.bn4b(self.conv4b(x)))\n","\n","        x = self.relu(self.bn5a(self.conv5a(x)))\n","        x = self.relu(self.bn5b(self.conv5b(x)))\n","        x = self.pool4(x)\n","\n","        x = self.flatten(x)\n","        x = self.relu(self.fc6(x))\n","        x = self.dropout(x)\n","        x = self.relu(self.fc7(x))\n","        x = self.dropout(x)\n","        x = self.fc8(x)\n","        x = self.softmax(x)\n","        return x"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T01:10:17.922489Z","iopub.status.busy":"2024-06-13T01:10:17.922236Z","iopub.status.idle":"2024-06-13T01:10:17.934345Z","shell.execute_reply":"2024-06-13T01:10:17.933616Z","shell.execute_reply.started":"2024-06-13T01:10:17.922462Z"},"trusted":true},"outputs":[],"source":["class LipReadingDataset(Dataset):\n","    def __init__(self, root_dir, phase='train', transform=None, fixed_frame_count=29, max_classes=500):\n","        self.root_dir = root_dir\n","        self.phase = phase\n","        self.transform = transform\n","        self.classes = sorted(os.listdir(root_dir))[:max_classes]\n","        self.files = []\n","        self.fixed_frame_count = fixed_frame_count\n","        \n","        for cls in self.classes:\n","            class_dir = os.path.join(root_dir, cls, phase)\n","            for file in os.listdir(class_dir):\n","                if file.endswith('.mp4'):\n","                    self.files.append((os.path.join(class_dir, file), cls))\n","        \n","    def __len__(self):\n","        return len(self.files)\n","        \n","    def __getitem__(self, idx):\n","        video_path, label = self.files[idx]\n","        frames = self.load_video(video_path)\n","        \n","        if self.transform:\n","            frames = [self.transform(frame) for frame in frames]\n","        \n","        label = self.classes.index(label)\n","        frames = torch.stack(frames)\n","        frames = frames.permute(1, 0, 2, 3)\n","        \n","        return frames, label\n","    \n","    def load_video(self, video_path):\n","        cap = cv2.VideoCapture(video_path)\n","        frames = []\n","        while cap.isOpened():\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","            frames.append(frame)\n","        cap.release()\n","        return frames"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T01:10:17.936659Z","iopub.status.busy":"2024-06-13T01:10:17.936379Z","iopub.status.idle":"2024-06-13T01:10:19.415320Z","shell.execute_reply":"2024-06-13T01:10:19.414362Z","shell.execute_reply.started":"2024-06-13T01:10:17.936637Z"},"trusted":true},"outputs":[],"source":["batch_size = 32\n","root_dir = '/kaggle/input/processed-25-lrw/preprocessed_25'\n","transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","train_dataset = LipReadingDataset(root_dir, 'train', transform=transform)\n","test_dataset = LipReadingDataset(root_dir, 'test', transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T01:10:19.417305Z","iopub.status.busy":"2024-06-13T01:10:19.416822Z","iopub.status.idle":"2024-06-13T01:10:19.446445Z","shell.execute_reply":"2024-06-13T01:10:19.445459Z","shell.execute_reply.started":"2024-06-13T01:10:19.417273Z"},"trusted":true},"outputs":[],"source":["def combine_batch_and_frames(in_vid):\n","    batch_size, channels, frames, x, y = in_vid.shape\n","    in_vid = in_vid.transpose(1,2)\n","    return in_vid.reshape(batch_size * frames, channels, x ,y)\n","\n","class ResBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(ResBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.downsample = nn.Sequential(\n","                                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n","                                nn.BatchNorm2d(out_channels),\n","                            )\n","        self.relu = nn.ReLU()\n","        \n","    \n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","        \n","class ResNet(nn.Module):\n","    def __init__(self):\n","        super(ResNet, self).__init__()\n","        self.layer1 = ResBlock(64, 64)\n","        self.layer2 = ResBlock(64, 128)\n","        self.layer3 = ResBlock(128, 256)\n","        self.layer4 = ResBlock(256, 512)\n","        self.avgpool = nn.AdaptiveAvgPool2d(1)\n","        \n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        return x\n","\n","class Chomp1d(nn.Module):\n","    def __init__(self, chomp_size):\n","        super(Chomp1d, self).__init__()\n","        self.chomp_size = chomp_size\n","\n","    def forward(self, x):\n","        return x[:, :, :-self.chomp_size].contiguous()\n","        \n","class TemporalBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride, dilation, padding, dropout=0.1):\n","        super(TemporalBlock, self).__init__()\n","        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation)\n","        self.chomp1 = Chomp1d(padding)\n","        self.bn1 = nn.BatchNorm1d(out_channels)\n","        self.relu1 = nn.ReLU()\n","        self.dropout1 = nn.Dropout(dropout)\n","\n","        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation)\n","        self.chomp2 = Chomp1d(padding)\n","        self.bn2 = nn.BatchNorm1d(out_channels)\n","        self.relu2 = nn.ReLU()\n","        self.dropout2 = nn.Dropout(dropout)\n","\n","        self.net = nn.Sequential(\n","            self.conv1, self.chomp1, self.bn1, self.relu1, self.dropout1,\n","            self.conv2, self.chomp2, self.bn2, self.relu2, self.dropout2\n","        )\n","        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        out = self.net(x)\n","        res = x if self.downsample is None else self.downsample(x)\n","        return self.relu(out + res)\n","\n","class TemporalConvNet(nn.Module):\n","    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.1):\n","        super(TemporalConvNet, self).__init__()\n","        layers = []\n","        num_levels = len(num_channels)\n","        for i in range(num_levels):\n","            dilation_size = 2 ** i\n","            in_channels = num_inputs if i == 0 else num_channels[i-1]\n","            out_channels = num_channels[i]\n","            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n","                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n","\n","        self.network = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return self.network(x)\n","\n","class LipReading(nn.Module):\n","    def __init__(self):\n","        super(LipReading, self).__init__()\n","        self.frontend3D = nn.Sequential(\n","                        nn.Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False),\n","                        nn.BatchNorm3d(64),\n","                        nn.ReLU(),\n","                        nn.MaxPool3d( kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1)))\n","        \n","        self.resnet = ResNet()\n","        self.tcn = TemporalConvNet(512, [32, 64, 128], kernel_size=3, dropout=0.3)\n","        self.linear = nn.Linear(128, 25)\n","        \n","    \n","    def forward(self, x):\n","        batch_size = x.shape[0]\n","        x = self.frontend3D(x)\n","        new_frames = x.shape[2]\n","        x = combine_batch_and_frames(x)\n","        x = self.resnet(x)\n","        x = x.view(batch_size, new_frames, x.size(1))\n","        x = x.transpose(1,2)\n","        x = self.tcn(x)\n","        x = torch.mean(x, dim=2)\n","        x = self.linear(x)\n","        return x\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#\n","#3dto2dtensor changes shape from (batch, channels, frames, x, y) to\n","# (batch * frames, channels, x, y)\n","# this shape is sent to resnet\n","# resnet runs conv2d's on this shape (idk why conv3x3 is a 2d conv really...)\n","#basic block is a conv2d, batch norm, relu, conv2d, batch norm, rlu\n","#resnet is 4 make_layers, where each make_layer is a loop making x \n","# number of layers with given channels\n","# layers is a len 4 array of 2's, so each make_layer makes 2 layers\n","# final is a block of 512 channels, idrk the x, y\n","# adaptiveavgpool takes avg of x, y; gets 512 channels of 1x1\n","# finally, rehsapes to (batch*frames, channels) and returns\n","# now, back in Lipreading module, we reshape back to (batch, frames, channels)\n","# this, we reshape into (batch, channels, frames) to run our 1d conv on\n","# TCN iterates across frames e.g. \n","#time = 1 to 25. kernel size of 3 goes 1 to 3, 2 to 4, 3 to 5, etc. \n","# In addition, it takes all 512 channels and dot products to create a single value\n","# which becomes the single element in the output\n","# There are out_channel channels in the output, so with proper padding,\n","# we still have 25 frames, but each input channel is used for every output channel\n","# and we have out_channel output_channels\n","\n","#Essentially, each conv1d is a weight matrix of size (in_channels, kernel_size)\n","# and we have out_channels number of these weight matrices\n","\n","#Then, we have n amount of these conv1d things in sequence, altering\n","#dilation, padding, and stride, so that each subsequent conv1d accesses\n","# a wider area, ultimately returning (batch size, output_channels, frames) shape\n","# this, we average over all the frames to get (batch_size, output_channels)\n","# finally, we pass this into a linear layer to get our final scores\n","\n","#What we have is the same frontend conv3d\n","#A miniature resnet with 2 64, 2 128, and 2 256 layers\n","# resulting in a (batch * frames, 256) output from resnet\n","#then 4 tcn layers\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T01:10:24.060841Z","iopub.status.busy":"2024-06-13T01:10:24.060432Z","iopub.status.idle":"2024-06-13T01:10:24.070316Z","shell.execute_reply":"2024-06-13T01:10:24.069178Z","shell.execute_reply.started":"2024-06-13T01:10:24.060808Z"},"trusted":true},"outputs":[],"source":["def evaluate_model(model, test_loader, device, criterion):\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    model.eval()  \n","    with torch.no_grad():  \n","        for batch_idx, (inputs, targets) in enumerate(test_loader):\n","            inputs, targets = inputs.to(device), targets.to(device)  \n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","    test_loss /= len(test_loader)\n","    accuracy = 100. * correct / total\n","    model.train()\n","    return test_loss, accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T23:36:46.244314Z","iopub.status.busy":"2024-06-12T23:36:46.243673Z","iopub.status.idle":"2024-06-12T23:48:04.079058Z","shell.execute_reply":"2024-06-12T23:48:04.077782Z","shell.execute_reply.started":"2024-06-12T23:36:46.244263Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","num_classes = len(train_dataset.classes)\n","learning_rate = 0.001\n","weight_decay = 0.001\n","num_epochs = 20\n","\n","model = LipReading()\n","model = nn.DataParallel(model)\n","model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n","\n","best_test_accuracy = 0\n","best_model = None\n","\n","train_losses = []\n","test_losses = []\n","test_accuracies = []\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    epoch_loss = 0.0\n","    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}')\n","    for videos, labels in progress_bar:\n","        videos = videos.to(device)\n","        labels = labels.to(device)\n","        outputs = model(videos)\n","        loss = criterion(outputs, labels)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","        progress_bar.set_postfix(loss=loss.item())\n","\n","    avg_loss = epoch_loss / len(train_loader)\n","    test_loss, test_accuracy = evaluate_model(model, test_loader, device, criterion)\n","    if test_accuracy > best_test_accuracy:\n","        best_test_accuracy = test_accuracy\n","        best_model = copy.deepcopy(model.state_dict())\n","    test_losses.append(test_loss)\n","    train_losses.append(avg_loss)\n","    test_accuracies.append(test_accuracy)\n","    print(f'Epoch [{epoch + 1}/{num_epochs}], Avg Loss: {avg_loss:.4f}, Test Loss: {test_loss: .4f} Testing Accuracy: {test_accuracy:.4f}')\n","    \n","    scheduler.step()  \n","\n","    \n","model_save_path = f'/kaggle/working/tcn_model25_less_channels_Acc{best_test_accuracy:2.0f}.pth'\n","torch.save(best_model, model_save_path)\n","print(f\"Model saved to {model_save_path}. Accuracy: {best_test_accuracy}\")\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T01:10:39.617596Z","iopub.status.busy":"2024-06-13T01:10:39.616796Z","iopub.status.idle":"2024-06-13T01:11:00.705363Z","shell.execute_reply":"2024-06-13T01:11:00.704437Z","shell.execute_reply.started":"2024-06-13T01:10:39.617566Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.7780043211502906 77.14285714285714\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","criterion = nn.CrossEntropyLoss()\n","\n","model = LipReading()\n","model = nn.DataParallel(model)\n","model.load_state_dict(torch.load('/kaggle/working/tcn_model25Acc77.pth'))\n","model.to(device)\n","test_loss, test_accuracy = evaluate_model(model, test_loader, device, criterion)\n","print(test_loss, test_accuracy)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T00:25:25.487566Z","iopub.status.busy":"2024-06-13T00:25:25.487176Z","iopub.status.idle":"2024-06-13T00:25:42.620891Z","shell.execute_reply":"2024-06-13T00:25:42.619921Z","shell.execute_reply.started":"2024-06-13T00:25:25.487525Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2.617603448721079 67.59183673469387\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","criterion = nn.CrossEntropyLoss()\n","\n","model = CNN(num_classes=25)\n","model = nn.DataParallel(model) #For 2 GPUs\n","model.load_state_dict(torch.load('/kaggle/input/cnn_25/pytorch/1/1/cnn_model_25.pth'))\n","model.to(device)\n","test_loss, test_accuracy = evaluate_model(model, test_loader, device, criterion)\n","print(test_loss, test_accuracy)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T01:14:18.414322Z","iopub.status.busy":"2024-06-13T01:14:18.413974Z","iopub.status.idle":"2024-06-13T01:14:18.424361Z","shell.execute_reply":"2024-06-13T01:14:18.423377Z","shell.execute_reply.started":"2024-06-13T01:14:18.414294Z"},"trusted":true},"outputs":[],"source":["def create_confusion_matrix(model, data_loader, device, criterion, path, classes):\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    all_preds = []\n","    all_targets = []\n","\n","    model.eval()  \n","    with torch.no_grad():  \n","        for inputs, targets in test_loader:\n","            inputs, targets = inputs.to(device), targets.to(device) \n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_targets.extend(targets.cpu().numpy())\n","\n","    test_loss /= len(test_loader)\n","    accuracy = 100. * correct / total\n","\n","    print(f'Accuracy: {accuracy:.2f}%')\n","    print(f'Test Loss: {test_loss:.6f}')\n","\n","    cm = confusion_matrix(all_targets, all_preds)\n","\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n","    disp.plot(cmap=plt.cm.Blues)\n","    plt.xticks(rotation=90)\n","    plt.savefig(path)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","criterion = nn.CrossEntropyLoss()\n","classes = sorted(os.listdir('/kaggle/input/processed-25-lrw/preprocessed_25'))\n","\n","model = CNN(num_classes=25)\n","model = nn.DataParallel(model) #For 2 GPUs\n","model.load_state_dict(torch.load('/kaggle/input/cnn_25/pytorch/1/1/cnn_model_25.pth'))\n","model.to(device)\n","create_confusion_matrix(model, test_loader, device, criterion, '/kaggle/working/cnn_confusion_mat', classes)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T01:14:20.714720Z","iopub.status.busy":"2024-06-13T01:14:20.713837Z","iopub.status.idle":"2024-06-13T01:14:34.737891Z","shell.execute_reply":"2024-06-13T01:14:34.736933Z","shell.execute_reply.started":"2024-06-13T01:14:20.714686Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","criterion = nn.CrossEntropyLoss()\n","classes = sorted(os.listdir('/kaggle/input/processed-25-lrw/preprocessed_25'))\n","\n","\n","model = LipReading()\n","model = nn.DataParallel(model) #For 2 GPUs\n","model.load_state_dict(torch.load('/kaggle/working/tcn_model25Acc77.pth'))\n","model.to(device)\n","create_confusion_matrix(model, test_loader, device, criterion, '/kaggle/working/tcn_confusion_mat', classes)\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5158404,"sourceId":8618182,"sourceType":"datasetVersion"},{"datasetId":5159347,"sourceId":8619447,"sourceType":"datasetVersion"},{"datasetId":5166073,"sourceId":8628540,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelInstanceId":51879,"sourceId":62108,"sourceType":"modelInstanceVersion"}],"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
