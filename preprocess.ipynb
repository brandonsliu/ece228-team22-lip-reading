{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotation_matrix(landmarks):\n",
    "    left_corner = np.array([landmarks.part(48).x, landmarks.part(48).y])\n",
    "    right_corner = np.array([landmarks.part(54).x, landmarks.part(54).y])\n",
    "\n",
    "    dy = right_corner[1] - left_corner[1]\n",
    "    dx = right_corner[0] - left_corner[0]\n",
    "    angle = np.degrees(np.arctan2(dy, dx))\n",
    "    \n",
    "    center = int((left_corner[0] + right_corner[0]) //2), int((left_corner[1] + right_corner[1]) // 2)\n",
    "\n",
    "    return cv2.getRotationMatrix2D(center, angle, 1.0), center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vid(face_detector, landmark_predictor, input_video_path, output_video_path, fps, width, height, output_size):\n",
    "    output_dir = os.path.dirname(output_video_path)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    vid_capture = cv2.VideoCapture(input_video_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (output_size, output_size), isColor=False)\n",
    "\n",
    "    while vid_capture.isOpened():\n",
    "        ret, frame = vid_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        faces = face_detector(gray)\n",
    "        \n",
    "        for face in faces:\n",
    "            landmarks = landmark_predictor(gray, face)\n",
    "            \n",
    "            M, center = get_rotation_matrix(landmarks)\n",
    "\n",
    "            gray_aligned = cv2.warpAffine(gray, M, (width, height))\n",
    "\n",
    "            x_min = center[0] - output_size // 2\n",
    "            y_min = center[1] - output_size // 2\n",
    "            x_max = x_min + output_size\n",
    "            y_max = y_min + output_size\n",
    "            \n",
    "            cropped_frame = np.zeros((output_size, output_size), dtype=np.uint8)\n",
    "\n",
    "            src_x_min = max(x_min, 0)\n",
    "            src_y_min = max(y_min, 0)\n",
    "            src_x_max = min(x_max, gray.shape[1])\n",
    "            src_y_max = min(y_max, gray.shape[0])\n",
    "            \n",
    "            dst_x_min = max(0, -x_min)\n",
    "            dst_y_min = max(0, -y_min)\n",
    "            dst_x_max = dst_x_min + (src_x_max - src_x_min)\n",
    "            dst_y_max = dst_y_min + (src_y_max - src_y_min)\n",
    "            \n",
    "            cropped_frame[dst_y_min:dst_y_max, dst_x_min:dst_x_max] = gray_aligned[src_y_min:src_y_max, src_x_min:src_x_max] \n",
    "            out.write(cropped_frame)\n",
    "            \n",
    "    vid_capture.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempt to normalize mouth size, doesn't look great but maybe later can try\n",
    "#Would go after gray_aligned creation in preprocess\n",
    "# lip_points = np.array([[landmarks.part(i).x, landmarks.part(i).y] for i in range(48, 61)])\n",
    "# lip_points = np.hstack([lip_points, np.ones((lip_points.shape[0], 1))])\n",
    "# rotated_lip_points = M.dot(lip_points.T).T\n",
    "# x_min, y_min = np.min(rotated_lip_points, axis=0)[:2].astype(int)\n",
    "# x_max, y_max = np.max(rotated_lip_points, axis=0)[:2].astype(int)\n",
    "\n",
    "# width_lips = x_max - x_min\n",
    "# height_lips = y_max - y_min\n",
    "\n",
    "# scale_x = (output_size * 0.5) / width_lips\n",
    "# scale_y = (output_size * 0.25) / height_lips\n",
    "\n",
    "# new_crop_width = output_size // scale_x\n",
    "# new_crop_height = output_size // scale_y\n",
    "\n",
    "# x_min = int(center[0] - new_crop_width // 2)\n",
    "# y_min = int(center[1] - new_crop_height // 2)\n",
    "# x_max = int(x_min + new_crop_width)\n",
    "# y_max = int(y_min + new_crop_height)\n",
    "\n",
    "\n",
    "# cropped_frame = gray_aligned[y_min:y_max, x_min:x_max]\n",
    "# resized_frame = cv2.resize(cropped_frame, (output_size, output_size))\n",
    "\n",
    "# out.write(resized_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()\n",
    "landmark_predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "source_root = 'selected_mp4_files'\n",
    "source_word = 'ABOUT'\n",
    "source_folder = 'train'\n",
    "input_video = 'ABOUT_00003.mp4'\n",
    "output_root = 'processed_selected_mp4_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ABOUT_00001():\n",
    "        input_video_path = os.path.join(source_root, source_word, 'train', input_video)\n",
    "        output_video_path = os.path.join(output_root, source_word, 'train', input_video)\n",
    "        process_vid(face_detector, landmark_predictor, input_video_path, output_video_path, fps=25, width=256, height=256, output_size=64)\n",
    "\n",
    "def test_ABOUT_whole():\n",
    "        start_time = time.time()\n",
    "        source_folder = os.path.join(source_root, source_word, 'train')\n",
    "        output_video_folder = os.path.join(output_root, source_word, 'train')\n",
    "        for input_video in sorted([file for file in os.listdir(source_folder) if file.endswith(\".mp4\")]):\n",
    "                input_video_path = os.path.join(source_folder, input_video)\n",
    "                output_video_path = os.path.join(output_video_folder, input_video)\n",
    "                process_vid(face_detector, landmark_predictor, input_video_path, output_video_path, fps=25, width=256, height=256, output_size=64)\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"Finished Processing ABOUT folder in {elapsed: .2f} seconds\")\n",
    "        \n",
    "\n",
    "def run_all():\n",
    "        start_time = time.time()\n",
    "        source_folders = [folder for folder in sorted(os.listdir(source_root)) if folder != '.DS_Store']\n",
    "\n",
    "        for source_word in source_folders:\n",
    "                source_folder = os.path.join(source_root, source_word, 'train')\n",
    "                output_video_folder = os.path.join(output_root, source_word, 'train')\n",
    "                for input_video in sorted([file for file in os.listdir(source_folder) if file.endswith(\".mp4\")]):\n",
    "                        input_video_path = os.path.join(source_folder, input_video)\n",
    "                        output_video_path = os.path.join(output_video_folder, input_video)\n",
    "                        process_vid(face_detector, landmark_predictor, input_video_path, output_video_path, fps=25, width=256, height=256, output_size=64)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f'Done in {elapsed_time: .2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook is used to preprocess the mp4's \n",
    "#It 1) centers, 2) horizontally aligns the mp4 around the lips center\n",
    "#3) Grayscale's the mp4, 4) Crops it to a 64x64 mp4\n",
    "#Then, it creates a new folder called \"processed_selected_mp4_files\" with the same\n",
    "#Structure as the lipread_mp4 data to store the new files\n",
    "#I ran it on mac so it might work differently on windows or something. \n",
    "#test_ABOUT_00001 preprocesses just ABOUT_00001.mpy\n",
    "#test_ABOUT_whole preprocesses the entire ABOUT train data\n",
    "#run_all preprocesses all the Words train set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece228-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
