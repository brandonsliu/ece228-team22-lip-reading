{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotation_matrix(landmarks):\n",
    "    left_corner = np.array([landmarks.part(48).x, landmarks.part(48).y])\n",
    "    right_corner = np.array([landmarks.part(54).x, landmarks.part(54).y])\n",
    "\n",
    "    dy = right_corner[1] - left_corner[1]\n",
    "    dx = right_corner[0] - left_corner[0]\n",
    "    angle = np.degrees(np.arctan2(dy, dx))\n",
    "    \n",
    "    center = int((left_corner[0] + right_corner[0]) //2), int((left_corner[1] + right_corner[1]) // 2)\n",
    "\n",
    "    return cv2.getRotationMatrix2D(center, angle, 1.0), center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vid(face_detector, landmark_predictor, input_video_path, output_video_path, fps, width, height, output_size):\n",
    "    vid_capture = cv2.VideoCapture(input_video_path)\n",
    "    num_frames = vid_capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    frame_count = 0;\n",
    "    cropped_frames = []\n",
    "    has_face = True;\n",
    "\n",
    "    if num_frames >= 29:\n",
    "        while vid_capture.isOpened():\n",
    "            ret, frame = vid_capture.read()\n",
    "            if not ret:\n",
    "                break\n",
    "        \n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            faces = face_detector(gray)\n",
    "            if len(faces) == 0:\n",
    "                has_face = False\n",
    "                break\n",
    "            face = faces[0]\n",
    "            landmarks = landmark_predictor(gray, face)\n",
    "            \n",
    "            M, center = get_rotation_matrix(landmarks)\n",
    "\n",
    "            gray_aligned = cv2.warpAffine(gray, M, (width, height))\n",
    "\n",
    "            x_min = center[0] - output_size // 2\n",
    "            y_min = center[1] - output_size // 2\n",
    "            x_max = x_min + output_size\n",
    "            y_max = y_min + output_size\n",
    "            \n",
    "            cropped_frame = np.zeros((output_size, output_size), dtype=np.uint8)\n",
    "\n",
    "            src_x_min = max(x_min, 0)\n",
    "            src_y_min = max(y_min, 0)\n",
    "            src_x_max = min(x_max, gray.shape[1])\n",
    "            src_y_max = min(y_max, gray.shape[0])\n",
    "            \n",
    "            dst_x_min = max(0, -x_min)\n",
    "            dst_y_min = max(0, -y_min)\n",
    "            dst_x_max = dst_x_min + (src_x_max - src_x_min)\n",
    "            dst_y_max = dst_y_min + (src_y_max - src_y_min)\n",
    "            \n",
    "            cropped_frame[dst_y_min:dst_y_max, dst_x_min:dst_x_max] = gray_aligned[src_y_min:src_y_max, src_x_min:src_x_max] \n",
    "            cropped_frames.append(cropped_frame)\n",
    "            frame_count += 1\n",
    "            if frame_count == 29:\n",
    "                break\n",
    "\n",
    "        if has_face:\n",
    "            output_dir = os.path.dirname(output_video_path)\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_video_path, fourcc, fps, (output_size, output_size), isColor=False)\n",
    "            for frame in cropped_frames:\n",
    "                out.write(frame)\n",
    "            out.release()\n",
    "            \n",
    "    vid_capture.release()\n",
    "    return has_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempt to normalize mouth size, doesn't look great but maybe later can try\n",
    "#Would go after gray_aligned creation in preprocess\n",
    "# lip_points = np.array([[landmarks.part(i).x, landmarks.part(i).y] for i in range(48, 61)])\n",
    "# lip_points = np.hstack([lip_points, np.ones((lip_points.shape[0], 1))])\n",
    "# rotated_lip_points = M.dot(lip_points.T).T\n",
    "# x_min, y_min = np.min(rotated_lip_points, axis=0)[:2].astype(int)\n",
    "# x_max, y_max = np.max(rotated_lip_points, axis=0)[:2].astype(int)\n",
    "\n",
    "# width_lips = x_max - x_min\n",
    "# height_lips = y_max - y_min\n",
    "\n",
    "# scale_x = (output_size * 0.5) / width_lips\n",
    "# scale_y = (output_size * 0.25) / height_lips\n",
    "\n",
    "# new_crop_width = output_size // scale_x\n",
    "# new_crop_height = output_size // scale_y\n",
    "\n",
    "# x_min = int(center[0] - new_crop_width // 2)\n",
    "# y_min = int(center[1] - new_crop_height // 2)\n",
    "# x_max = int(x_min + new_crop_width)\n",
    "# y_max = int(y_min + new_crop_height)\n",
    "\n",
    "\n",
    "# cropped_frame = gray_aligned[y_min:y_max, x_min:x_max]\n",
    "# resized_frame = cv2.resize(cropped_frame, (output_size, output_size))\n",
    "\n",
    "# out.write(resized_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_00001(face_detector, landmark_predictor, source_root, output_root, source_word, mode, input_video):\n",
    "        input_video_path = os.path.join(source_root, source_word, mode, input_video)\n",
    "        output_video_path = os.path.join(output_root, source_word, mode, input_video)\n",
    "        process_vid(face_detector, landmark_predictor, input_video_path, output_video_path, fps=25, width=256, height=256, output_size=64)\n",
    "\n",
    "def test_whole(face_detector, landmark_predictor, source_root, output_root, source_word, mode):\n",
    "        start_time = time.time()\n",
    "        source_folder = os.path.join(source_root, source_word, mode)\n",
    "        output_video_folder = os.path.join(output_root, source_word, mode)\n",
    "        added = 0\n",
    "        for input_video in sorted([file for file in os.listdir(source_folder) if file.endswith(\".mp4\")]):\n",
    "                input_video_path = os.path.join(source_folder, input_video)\n",
    "                output_video_path = os.path.join(output_video_folder, input_video)\n",
    "                has_face = process_vid(face_detector, landmark_predictor, input_video_path, output_video_path, fps=25, width=256, height=256, output_size=64)\n",
    "                if has_face:\n",
    "                        added += 1\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"Finished Processing {source_word} folder in {elapsed: .2f} seconds\")\n",
    "        return added\n",
    "        \n",
    "\n",
    "def run_all(face_detector, landmark_predictor, source_root, output_root, mode):\n",
    "        start_time = time.time()\n",
    "        source_folders = [folder for folder in sorted(os.listdir(source_root)) if folder != '.DS_Store']\n",
    "\n",
    "        for source_word in source_folders:\n",
    "                print(f\"Processing word {source_word}...\")\n",
    "                source_folder = os.path.join(source_root, source_word, mode)\n",
    "                output_video_folder = os.path.join(output_root, source_word, mode)\n",
    "                for input_video in sorted([file for file in os.listdir(source_folder) if file.endswith(\".mp4\")]):\n",
    "                        input_video_path = os.path.join(source_folder, input_video)\n",
    "                        output_video_path = os.path.join(output_video_folder, input_video)\n",
    "                        process_vid(face_detector, landmark_predictor, input_video_path, output_video_path, fps=25, width=256, height=256, output_size=64)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f'Done in {elapsed_time: .2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ISLAMIC', 'ISSUE', 'ISSUES', 'ITSELF', 'JAMES', 'JUDGE', 'JUSTICE', 'KILLED', 'KNOWN', 'LABOUR', 'LARGE', 'LATER', 'LATEST', 'LEADER', 'LEADERS', 'LEADERSHIP', 'LEAST', 'LEAVE', 'LEGAL', 'LEVEL', 'LEVELS', 'LIKELY', 'LITTLE', 'LIVES', 'LIVING', 'LOCAL', 'LONDON', 'LONGER', 'LOOKING', 'MAJOR', 'MAJORITY', 'MAKES', 'MAKING', 'MANCHESTER', 'MARKET', 'MASSIVE', 'MATTER', 'MAYBE', 'MEANS', 'MEASURES', 'MEDIA', 'MEDICAL', 'MEETING', 'MEMBER', 'MEMBERS', 'MESSAGE', 'MIDDLE', 'MIGHT', 'MIGRANTS', 'MILITARY', 'MILLION', 'MILLIONS', 'MINISTER', 'MINISTERS', 'MINUTES', 'MISSING', 'MOMENT', 'MONEY', 'MONTH', 'MONTHS', 'MORNING', 'MOVING', 'MURDER', 'NATIONAL', 'NEEDS', 'NEVER', 'NIGHT', 'NORTH', 'NORTHERN', 'NOTHING', 'NUMBER', 'NUMBERS', 'OBAMA', 'OFFICE', 'OFFICERS', 'OFFICIALS', 'OFTEN', 'OPERATION', 'OPPOSITION', 'ORDER', 'OTHER', 'OTHERS', 'OUTSIDE', 'PARENTS', 'PARLIAMENT', 'PARTIES', 'PARTS', 'PARTY', 'PATIENTS', 'PAYING', 'PEOPLE', 'PERHAPS', 'PERIOD', 'PERSON', 'PERSONAL', 'PHONE', 'PLACE', 'PLACES', 'PLANS', 'POINT', 'POLICE', 'POLICY', 'POLITICAL', 'POLITICIANS', 'POLITICS', 'POSITION', 'POSSIBLE', 'POTENTIAL', 'POWER', 'POWERS', 'PRESIDENT', 'PRESS', 'PRESSURE', 'PRETTY', 'PRICE', 'PRICES', 'PRIME', 'PRISON', 'PRIVATE', 'PROBABLY', 'PROBLEM', 'PROBLEMS', 'PROCESS', 'PROTECT', 'PROVIDE', 'PUBLIC', 'QUESTION', 'QUESTIONS', 'QUITE', 'RATES', 'RATHER', 'REALLY', 'REASON', 'RECENT', 'RECORD', 'REFERENDUM', 'REMEMBER', 'REPORT', 'REPORTS', 'RESPONSE', 'RESULT', 'RETURN', 'RIGHT', 'RIGHTS', 'RULES', 'RUNNING', 'RUSSIA', 'RUSSIAN', 'SAYING', 'SCHOOL', 'SCHOOLS', 'SCOTLAND', 'SCOTTISH', 'SECOND', 'SECRETARY', 'SECTOR', 'SECURITY', 'SEEMS', 'SENIOR', 'SENSE', 'SERIES', 'SERIOUS', 'SERVICE', 'SERVICES', 'SEVEN', 'SEVERAL', 'SHORT', 'SHOULD', 'SIDES', 'SIGNIFICANT', 'SIMPLY', 'SINCE', 'SINGLE', 'SITUATION', 'SMALL', 'SOCIAL', 'SOCIETY', 'SOMEONE', 'SOMETHING', 'SOUTH', 'SOUTHERN', 'SPEAKING', 'SPECIAL', 'SPEECH', 'SPEND', 'SPENDING', 'SPENT', 'STAFF', 'STAGE', 'STAND', 'START', 'STARTED', 'STATE', 'STATEMENT', 'STATES', 'STILL', 'STORY', 'STREET', 'STRONG', 'SUNDAY', 'SUNSHINE', 'SUPPORT', 'SYRIA', 'SYRIAN', 'SYSTEM', 'TAKEN', 'TAKING', 'TALKING', 'TALKS', 'TEMPERATURES', 'TERMS', 'THEIR', 'THEMSELVES', 'THERE', 'THESE', 'THING', 'THINGS', 'THINK', 'THIRD', 'THOSE', 'THOUGHT', 'THOUSANDS', 'THREAT', 'THREE', 'THROUGH', 'TIMES', 'TODAY', 'TOGETHER', 'TOMORROW', 'TONIGHT', 'TOWARDS', 'TRADE', 'TRIAL', 'TRUST', 'TRYING', 'UNDER', 'UNDERSTAND', 'UNION', 'UNITED', 'UNTIL', 'USING', 'VICTIMS', 'VIOLENCE', 'VOTERS', 'WAITING', 'WALES', 'WANTED', 'WANTS', 'WARNING', 'WATCHING', 'WATER', 'WEAPONS', 'WEATHER', 'WEEKEND', 'WEEKS', 'WELCOME', 'WELFARE', 'WESTERN', 'WESTMINSTER', 'WHERE', 'WHETHER', 'WHICH', 'WHILE', 'WHOLE', 'WINDS', 'WITHIN', 'WITHOUT', 'WOMEN', 'WORDS', 'WORKERS', 'WORKING', 'WORLD', 'WORST', 'WOULD', 'WRONG', 'YEARS', 'YESTERDAY', 'YOUNG']\n"
     ]
    }
   ],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()\n",
    "landmark_predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "source_root = 'selected_mp4_files'\n",
    "source_word = 'CHINA'\n",
    "mode = 'test'\n",
    "input_video = 'ABOUT_00002.mp4'\n",
    "output_root = 'preprocessed_25'\n",
    "#This notebook is used to preprocess the mp4's \n",
    "#It 1) centers, 2) horizontally aligns the mp4 around the lips center\n",
    "#3) Grayscale's the mp4, 4) Crops it to a 64x64 mp4\n",
    "#Then, it creates a new folder called \"processed_selected_mp4_files\" with the same\n",
    "#Structure as the lipread_mp4 data to store the new files\n",
    "#I ran it on mac so it might work differently on windows or something. \n",
    "#test_ABOUT_00001 preprocesses just ABOUT_00001.mpy\n",
    "#test_ABOUT_whole preprocesses the entire ABOUT train data\n",
    "#run_all preprocesses all the Words train set\n",
    "class_names = sorted(os.listdir(source_root))\n",
    "class_names = [name for name in class_names if name != '.DS_Store' and name > 'IRELAND']\n",
    "# chosen_names = np.random.choice(class_names, 25)\n",
    "print(class_names)\n",
    "# run_all(face_detector, landmark_predictor, source_root, output_root, 'train')\n",
    "# run_all(face_detector, landmark_predictor, source_root, output_root, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SIDES' 'PLACE' 'LEAVE' 'SHOULD' 'HAPPENING' 'FAMILIES' 'SENIOR' 'LIVES'\n",
      " 'STAGE' 'COMMUNITY' 'EDUCATION' 'TALKING' 'HOUSING' 'GETTING' 'LOOKING'\n",
      " 'WEEKS' 'FOUND' 'AGAIN' 'SERIOUS' 'INQUIRY' 'WITHIN' 'WHILE' 'LIVING'\n",
      " 'TONIGHT' 'PERSON']\n",
      "Finished Processing SIDES folder in  16.78 seconds\n",
      "Finished Processing SIDES folder in  64.33 seconds\n",
      "Finished Processing PLACE folder in  15.32 seconds\n",
      "Finished Processing PLACE folder in  66.03 seconds\n",
      "Finished Processing LEAVE folder in  14.63 seconds\n",
      "Finished Processing LEAVE folder in  64.60 seconds\n",
      "Finished Processing SHOULD folder in  15.07 seconds\n",
      "Finished Processing SHOULD folder in  64.73 seconds\n",
      "Finished Processing HAPPENING folder in  15.98 seconds\n",
      "Finished Processing HAPPENING folder in  64.08 seconds\n",
      "Finished Processing FAMILIES folder in  14.94 seconds\n",
      "Finished Processing FAMILIES folder in  59.79 seconds\n",
      "Finished Processing SENIOR folder in  14.66 seconds\n",
      "Finished Processing SENIOR folder in  64.42 seconds\n",
      "Finished Processing LIVES folder in  15.55 seconds\n",
      "Finished Processing LIVES folder in  63.84 seconds\n",
      "Finished Processing STAGE folder in  15.01 seconds\n",
      "Finished Processing STAGE folder in  63.56 seconds\n",
      "Finished Processing COMMUNITY folder in  15.21 seconds\n",
      "Finished Processing COMMUNITY folder in  65.95 seconds\n",
      "Finished Processing EDUCATION folder in  16.84 seconds\n",
      "Finished Processing EDUCATION folder in  67.11 seconds\n",
      "Finished Processing TALKING folder in  15.85 seconds\n",
      "Finished Processing TALKING folder in  64.05 seconds\n",
      "Finished Processing HOUSING folder in  15.98 seconds\n",
      "Finished Processing HOUSING folder in  66.89 seconds\n",
      "Finished Processing GETTING folder in  15.78 seconds\n",
      "Finished Processing GETTING folder in  65.90 seconds\n",
      "Finished Processing LOOKING folder in  15.92 seconds\n",
      "Finished Processing LOOKING folder in  62.75 seconds\n",
      "Finished Processing WEEKS folder in  16.32 seconds\n",
      "Finished Processing WEEKS folder in  66.05 seconds\n",
      "Finished Processing FOUND folder in  14.84 seconds\n",
      "Finished Processing FOUND folder in  65.85 seconds\n",
      "Finished Processing AGAIN folder in  15.29 seconds\n",
      "Finished Processing AGAIN folder in  64.26 seconds\n",
      "Finished Processing SERIOUS folder in  16.63 seconds\n",
      "Finished Processing SERIOUS folder in  66.23 seconds\n",
      "Finished Processing INQUIRY folder in  15.72 seconds\n",
      "Finished Processing INQUIRY folder in  65.68 seconds\n",
      "Finished Processing WITHIN folder in  16.27 seconds\n",
      "Finished Processing WITHIN folder in  65.99 seconds\n",
      "Finished Processing WHILE folder in  16.20 seconds\n",
      "Finished Processing WHILE folder in  64.11 seconds\n",
      "Finished Processing LIVING folder in  15.60 seconds\n",
      "Finished Processing LIVING folder in  63.93 seconds\n",
      "Finished Processing TONIGHT folder in  16.23 seconds\n",
      "Finished Processing TONIGHT folder in  65.24 seconds\n",
      "Finished Processing PERSON folder in  15.48 seconds\n",
      "Finished Processing PERSON folder in  66.11 seconds\n"
     ]
    }
   ],
   "source": [
    "for name in class_names:\n",
    "    test_whole(face_detector, landmark_predictor, source_root, output_root, name, 'test')\n",
    "    test_whole(face_detector, landmark_predictor, source_root, output_root, name, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece228-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
